# Модуль 3 - Контролируемая классификация

Контролируемая классификация, пожалуй, является наиболее важным классическим методом машинного обучения в дистанционном зондировании. Область применения варьируется от создания карт землепользования/растительного покрова до обнаружения изменений. Google Earth Engine идеально подходит для проведения контролируемой классификации в масштабе. Интерактивный характер разработки Earth Engine позволяет итеративно разрабатывать рабочие процессы контролируемой классификации, объединяя в модели множество различных наборов данных. Этот модуль охватывает базовый рабочий процесс контролируемой классификации, оценку точности, настройку гиперпараметров и обнаружение изменений.

## 01. Простая контролируемая классификация

Мы узнаем, как выполнить базовую классификацию растительного покрова, используя обучающие выборки, собранные в редакторе кода с использованием изображений базовой карты высокого разрешения, предоставленных Google Maps. Этот метод не требует предварительного обучения и достаточно эффективен для создания высококачественных классификационных выборок в любой точке мира. Цель состоит в том, чтобы классифицировать каждый исходный пиксель по одному из следующих классов - городской, голый, водный или растительный. Используя инструменты рисования в редакторе кода, вы создаете 4 новых набора объектов с точками, представляющими пиксели этого класса. Каждая коллекция объектов имеет свойство landcover со значениями 0, 1, 2 или 3, указывающее, представляет ли коллекция объектов городскую местность, пустыню, воду или растительность соответственно. Затем мы обучаем классификатор случайных лесов, используя этот обучающий набор, чтобы построить модель и применить ее ко всем пикселям изображения, чтобы создать изображение 4-го класса.

!!! abstract "Интересный факт"
    Классификаторы в API Earth Engine имеют имена, начинающиеся на smile, например, `ee.Classifier.smileRandomForest()`. Часть smile относится к JAVA-библиотеке [статистического машинного интеллекта и механизма обучения (SMILE)](https://haifengl.github.io/index.html), которая используется Google Earth Engine для реализации этих алгоритмов.

<figure markdown>
  ![[03_01_1.jpg]]
  <figcaption>Результат контролируемой классификации</figcaption>
</figure>

```js
var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');

// Выполните контролируемую классификацию для вашего города

// Удалите геометрию, приведенную ниже, и нарисуйте многоугольник
// над выбранным вами городом
var geometry = ee.Geometry.Polygon([[
  [77.4149, 13.1203],
  [77.4149, 12.7308],
  [77.8090, 12.7308],
  [77.8090, 13.1203]
]]);
          
Map.centerObject(geometry);

var filtered = s2
.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date('2019-01-01', '2020-01-01'))
  .filter(ee.Filter.bounds(geometry))
  .select('B.*');

var composite = filtered.median();

// Отобразить составной элемент ввода.

var rgbVis = {min: 0.0, max: 3000, bands: ['B4', 'B3', 'B2']};
Map.addLayer(composite.clip(geometry), rgbVis, 'image');

// Упражнение
// Добавьте тренировочные баллы за 4 занятия
// Присвоите свойству "наземный покров" следующее значение

// urban: 0
// bare: 1
// water: 2
// vegetation: 3

var urban = ee.FeatureCollection('users/ujavalgandhi/e2e/urban_gcps');
var bare = ee.FeatureCollection('users/ujavalgandhi/e2e/bare_gcps');
var water = ee.FeatureCollection('users/ujavalgandhi/e2e/water_gcps');
var vegetation = ee.FeatureCollection('users/ujavalgandhi/e2e/vegetation_gcps');

// После добавления точек, раскомментируйте строчки ниже

var gcps = urban.merge(bare).merge(water).merge(vegetation);

// Добавьте точки поверх картинки, чтобы получить данные для обучения
var training = composite.sampleRegions({
  collection: gcps, 
   properties: ['landcover'], 
   scale: 10,
   tileScale: 16
 });
print(training);


 // Обучите классификатор
 var classifier = ee.Classifier.smileRandomForest(50).train({
   features: training,  
   classProperty: 'landcover', 
   inputProperties: composite.bandNames()
 });
 // Произведите классификацию снимка
 var classified = composite.classify(classifier);

 // Выберете 4-цветную палитру
 // Присвойте цвет каждому классу:
 // Urban, Bare, Water, Vegetation
var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];

Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019');
```

## 02. Оценка точности

Важно получить количественную оценку точности классификации. Для этого обычная стратегия заключается в разделении обучающих выборок на 2 случайные части - одна используется для обучения модели, а другая - для проверки прогнозов. После того, как классификатор обучен, его можно использовать для классификации всего изображения. Затем мы можем сравнить классифицированные значения с теми, которые указаны в проверочной части. Мы можем использовать метод `ee.Classifier.confusionMatrix()` для вычисления матрицы путаницы, представляющей ожидаемую точность.

Результаты классификации оцениваются на основе следующих показателей

- Общая точность: сколько образцов было классифицировано правильно.
- Точность производителя: насколько хорошо классификация предсказала каждый класс.
- Точность потребителя (надежность): Насколько надежен прогноз для каждого класса.
- Коэффициент Каппа: насколько хорошо была выполнена классификация по сравнению со случайным распределением.

<figure markdown>
  ![[03_02_1.jpg]]
  <figcaption>Оценка точности</figcaption>
</figure>

!!! warning "Внимание"
    Не увлекайтесь настройкой своей модели, чтобы добиться максимальной точности проверки. Для оценки результатов необходимо использовать как качественные показатели (например, визуальный контроль результатов), так и количественные показатели.

```js
var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');
var basin = ee.FeatureCollection("WWF/HydroSHEDS/v1/Basins/hybas_7");
var gcp = ee.FeatureCollection("users/ujavalgandhi/e2e/arkavathy_gcps");
    
var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: ['B4', 'B3', 'B2'],
};
 
var filtered = s2
.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date('2019-01-01', '2020-01-01'))
  .filter(ee.Filter.bounds(geometry))
  .select('B.*');

var composite = filtered.median();

// Отобразить составной элемент ввода.
Map.addLayer(composite.clip(geometry), rgbVis, 'image');


// Добавьте случайный столбец и разделите GCP на обучающий и проверочный наборы
var gcp = gcp.randomColumn();

// Поскольку это более простая классификация, мы берем 60% размер валидационной выборки
// Обычно рекомендуемое соотношение составляет
// 70% обучающая, 30% валидационная
var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6));

// Наложите точку на изображение, чтобы получить обучающие данные.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});

// Обучите классификатор.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: composite.bandNames()
});


// Classify the image.
var classified = composite.classify(classifier);

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019');
//************************************************************************** 
// Оценка точности
//************************************************************************** 

// Используйте классификационную карту для оценки точности с использованием валидационной доли
// из общей обучающей выборки, созданной выше.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  tileScale: 16,
  scale: 10,
});

var testConfusionMatrix = test.errorMatrix('landcover', 'classification')
// На вывод матрицы ошибок может уйти много времени. Вы можете экспортировать её в csv
print('Confusion Matrix', testConfusionMatrix);
print('Test Accuracy', testConfusionMatrix.accuracy());

// Альтернативный способ
// Похоже на практики машинного обучения
var validation = composite.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});

var test = validation.classify(classifier);

var testConfusionMatrix = test.errorMatrix('landcover', 'classification')
// На вывод матрицы ошибок может уйти много времени. Вы можете экспортировать её в csv
print('Confusion Matrix', testConfusionMatrix);
print('Test Accuracy', testConfusionMatrix.accuracy());
```

### Упражнение

```js
var composite = ee.Image('users/ujavalgandhi/e2e/arkavathy_2019_composite');
var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps');
var gcp = gcp.randomColumn();

var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6));

var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});

// Обучите классификатор.
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: composite.bandNames()
});

// Произведите классификацю изображения.
var classified = composite.classify(classifier);

//************************************************************************** 
// Оценка точности
//************************************************************************** 

// Используйте классификационную карту для оценки точности с использованием валидационной доли
// из общей обучающей выборки, созданной выше.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  tileScale: 16,
  scale: 10,
});

var testConfusionMatrix = test.errorMatrix('landcover', 'classification');
print('Confusion Matrix', testConfusionMatrix);
print('Test Accuracy', testConfusionMatrix.accuracy());

// Упражнение

// Рассчитайте и выведите следующие метрики
// 1. Producer's accuracy
// 2. Consumer's accuracy
// 3. F1-score

// Подсказка: в модуле ee.ConfusionMatrix находятся нужные методы
```

## 03. Улучшаем классификацию


Модель данных Землю двигателя особенно хорошо подходит для задач машинного обучения, поскольку она позволяет легко объединять источники данных с различными пространственными разрешениями, проекциями и типами данных, предоставляя дополнительную информацию классификатору, что позволяет легко разделять различные классы. Здесь мы возьмем тот же пример и дополним его следующими приемами.

- Применить маскировку облаком
- Добавить спектральные индексы: Диапазоны для различных спектральных индексов, таких как - NDVI, NDBI, NDVI и BSI.
- Добавление высоты и наклона: Мы также добавляем полосы наклона и высоты из ALOS DEM.
- Нормализуйте входные данные: модели машинного обучения работают лучше всего, когда все входные данные имеют одинаковый масштаб. Мы будем делить каждый диапазон на максимальное значение. Этот метод гарантирует, что все входные значения будут находиться в диапазоне от 0 до 1. Более полная и надежная методика нормализации изображений представлена в дополнении к курсу.

Наши обучающие функции имеют больше параметров и содержат значения по той же шкале. В результате мы получили значительно улучшенную классификацию.

<figure markdown>
  ![[03_03_1.jpg]]
  <figcaption>Результат улучшенной классификации</figcaption>
</figure>

<figure markdown>
  ![[03_03_2.jpg]]
  <figcaption>Вывод улучшенной классификации (исходя из точности)</figcaption>
</figure>

```js
var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');
var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7');
var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps');
var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2');


var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var filtered = s2
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date('2019-01-01', '2020-01-01'))
  .filter(ee.Filter.bounds(geometry));

// Загрузите коллекцию Cloud Score+
var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');
var csPlusBands = csPlus.first().bandNames();

// Нам нужно добавить Cloud Score + каналы от каждого снимка от Sentinel-2
// Это делается через функцию linkCollection()
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Функция для маскировки пикселей с низким значением CS+ QA
function maskLowQA(image) {
  var qaBand = 'cs';
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select('B.*');

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']);
  var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']);
  var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); 
  var bsi = image.expression(
      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {
        'X': image.select('B11'), //swir1
        'Y': image.select('B4'),  //red
        'A': image.select('B8'), // nir
        'B': image.select('B2'), // blue
  }).rename('bsi');
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);

// Вычисляем уклон и высоту над уровнем моря

// Используем ALOS World 3D v3

// Это набор изображений
// Мы объединяем их в мозаику, чтобы создать единое изображение

// Необходимо правильно настроить проекцию на мозаику
// для вычисления уклона
var proj = alos.first().projection();

var elevation = alos.select('DSM').mosaic()
  .setDefaultProjection(proj)
  .rename('elev');

var slope = ee.Terrain.slope(elevation)
  .rename('slope');

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, 'RGB');

// Нормализовать изображение 

// Алгоритмы машинного обучения лучше всего работают с изображениями, когда все элементы имеют
// одинаковый диапазон

// Функция для нормализации изображения
// Значения в пикселях должны быть от 0 до 1
// Формула (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Вычислим минимум и максимум на снимке
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Добавьте случайную колонку и разделите GCP на обучающую и валидационную выборки
var gcp = gcp.randomColumn();


// Поскольку это более простая классификация, мы берем 60% размер валидационной выборки
// Обычно рекомендуемое соотношение составляет
// 70% обучающая, 30% валидационная
var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6));

// Наложите точку на изображение, чтобы получить обучающие данные.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});
print(training);

// Обучите классификатор
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: composite.bandNames()
});

// Произведите классификацию снимка
var classified = composite.classify(classifier);

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019');

//************************************************************************** 
// Оценка точности
//************************************************************************** 

// Используйте классификационную карту для оценки точности с использованием валидационной доли
// из общей обучающей выборки, созданной выше.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});

var testConfusionMatrix = test.errorMatrix('landcover', 'classification');

// На вывод матрицы ошибок может уйти много времени. Вы можете экспортировать её в csv
print('Confusion Matrix', testConfusionMatrix);
print('Test Accuracy', testConfusionMatrix.accuracy());
```

### Упражнение

```js
// Улучшите классификатор в упражнении 01с 
// Добавьте различные спектральные показатели в свой составной материал
// с помощью функции, приведенной ниже

var addIndices = function(image) {
  var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']);
  var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']);
  var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); 
  var bsi = image.expression(
      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {
        'X': image.select('B11'), // swir1
        'Y': image.select('B4'),  // red
        'A': image.select('B8'),  // nir
        'B': image.select('B2'),  // blue
  }).rename('bsi');
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};
```

## 04. Экспорт результатов классификации

При работе со сложными классификаторами в больших областях в редакторе кода может быть превышен лимит пользовательской памяти или ошибка тайм-аута вычислений. Причина этого заключается в том, что существует фиксированный лимит времени и меньше памяти выделяется для кода, который выполняется в режиме вычислений по требованию. Для больших вычислений вы можете использовать пакетный режим с функциями экспорта. Экспорт выполняется в фоновом режиме и может длиться более 5 минут, выделенных на выполнение вычислительного кода из редактора кода. Это позволяет обрабатывать очень большие и сложные наборы данных. Вот пример, показывающий, как экспортировать результаты классификации на Google Диск.

<figure markdown>
  ![[03_04_1.jpg]]
  <figcaption>Экпортированные результаты классификации</figcaption>
</figure>

```js
var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');
var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7');
var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps');
var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2');


var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: ['B4', 'B3', 'B2'],
};

var filtered = s2
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date('2019-01-01', '2020-01-01'))
  .filter(ee.Filter.bounds(geometry))

// Загрузите коллекцию Cloud Score+
var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');
var csPlusBands = csPlus.first().bandNames();

// Нам нужно добавить Cloud Score + каналы от каждого снимка от Sentinel-2
// Это делается через функцию linkCollection()
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Функция для маскировки пикселей с низким значением CS+ QA
function maskLowQA(image) {
  var qaBand = 'cs';
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select('B.*');

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']);
  var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']);
  var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); 
  var bsi = image.expression(
      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {
        'X': image.select('B11'), //swir1
        'Y': image.select('B4'),  //red
        'A': image.select('B8'), // nir
        'B': image.select('B2'), // blue
  }).rename('bsi');
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);


// Вычисляем уклон и высоту над уровнем моря

// Используем ALOS World 3D v3

// Это набор изображений
// Мы объединяем их в мозаику, чтобы создать единое изображение

// Необходимо правильно настроить проекцию на мозаику
// для вычисления уклона
var proj = alos.first().projection();

var elevation = alos.select('DSM').mosaic()
  .setDefaultProjection(proj)
  .rename('elev');

var slope = ee.Terrain.slope(elevation)
  .rename('slope');

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, 'RGB');

// Нормализовать изображение 

// Алгоритмы машинного обучения лучше всего работают с изображениями, когда все элементы имеют
// одинаковый диапазон

// Функция для нормализации изображения
// Значения в пикселях должны быть от 0 до 1
// Формула (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Вычислим минимум и максимум на снимке
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// Поскольку это более простая классификация, мы берем 60% размер валидационной выборки
// Обычно рекомендуемое соотношение составляет
// 70% обучающая, 30% валидационная
var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6));

// Наложите точку на изображение, чтобы получить обучающие данные.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});
print(training);

// Обучите классификатор
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: composite.bandNames()
});

// Произведите классификацию снимка
var classified = composite.classify(classifier);

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019');

//************************************************************************** 
// Оценка точности
//************************************************************************** 

// Используйте классификационную карту для оценки точности с использованием валидационной доли
// из общей обучающей выборки, созданной выше.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});

var testConfusionMatrix = test.errorMatrix('landcover', 'classification');

//************************************************************************** 
// Экспорт результатов
//************************************************************************** 

// Экспортируйте классифицированный снимок на Google Drive

// Для изображений, содержащих целые числа (например, номера классов)
// мы приводим изображение к типу данных с плавающей запятой, который
// позволяет сохранять замаскированные значения как значения NaN
// в формате GeoTIFF.
// Вы можете установить для них фактические значения NoData, используя
// Инструменты GDAL после экспорта
// gdal_translate -a_nodata 'nan' input.tif output.tif
Export.image.toDrive({
  image: classified.clip(geometry).toFloat(),
  description: 'Classified_Image_Export',
  folder: 'earthengine',
  fileNamePrefix: 'classified',
  region: geometry,
  scale: 10,
  maxPixels: 1e10
})

// Экспортируем результаты оценки точности

// Создаем объект с нулевой геометрией и значением, которое мы хотим экспортировать.
// Используем .array() для преобразования матрицы путаницы в массив, чтобы ее можно было
// экспортировать в CSV-файл.
var fc = ee.FeatureCollection([
  ee.Feature(null, {
    'accuracy': testConfusionMatrix.accuracy(),
    'matrix': testConfusionMatrix.array()
  })
]);

print(fc);

Export.table.toDrive({
  collection: fc,
  description: 'Accuracy_Assessment_Export',
  folder: 'earthengine',
  fileNamePrefix: 'accuracy',
  fileFormat: 'CSV'
});
```

### Упражнение

Также рекомендуется экспортировать классифицированное изображение в качестве ресурса. Это позволит вам импортировать классифицированное изображение в другой сценарий без выполнения всего процесса классификации. Используйте функцию `Export.image.toAsset()` для экспорта классифицированного изображения в качестве ресурса

```js
var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');
var basin = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7');
var gcp = ee.FeatureCollection('users/ujavalgandhi/e2e/arkavathy_gcps');
var alos = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2');


var arkavathy = basin.filter(ee.Filter.eq('HYBAS_ID', 4071139640));
var geometry = arkavathy.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: ['B4', 'B3', 'B2'],
};

var filtered = s2
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date('2019-01-01', '2020-01-01'))
  .filter(ee.Filter.bounds(geometry))

// Загрузите коллекцию Cloud Score+
var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');
var csPlusBands = csPlus.first().bandNames();

// Нам нужно добавить Cloud Score + каналы от каждого снимка от Sentinel-2
// Это делается через функцию linkCollection()
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Функция для маскировки пикселей с низким значением CS+ QA
function maskLowQA(image) {
  var qaBand = 'cs';
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select('B.*');

var composite = filteredMasked.median();

var addIndices = function(image) {
  var ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi']);
  var ndbi = image.normalizedDifference(['B11', 'B8']).rename(['ndbi']);
  var mndwi = image.normalizedDifference(['B3', 'B11']).rename(['mndwi']); 
  var bsi = image.expression(
      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {
        'X': image.select('B11'), //swir1
        'Y': image.select('B4'),  //red
        'A': image.select('B8'), // nir
        'B': image.select('B2'), // blue
  }).rename('bsi');
  return image.addBands(ndvi).addBands(ndbi).addBands(mndwi).addBands(bsi);
};

var composite = addIndices(composite);

// Вычисляем уклон и высоту над уровнем моря

// Используем ALOS World 3D v3

// Это набор изображений
// Мы объединяем их в мозаику, чтобы создать единое изображение

// Необходимо правильно настроить проекцию на мозаику
// для вычисления уклона
var proj = alos.first().projection();

var elevation = alos.select('DSM').mosaic()
  .setDefaultProjection(proj)
  .rename('elev');

var slope = ee.Terrain.slope(elevation)
  .rename('slope');

var composite = composite.addBands(elevation).addBands(slope);
var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000, gamma: 1.2};
Map.addLayer(composite.clip(geometry), visParams, 'RGB');

// Нормализовать изображение 

// Алгоритмы машинного обучения лучше всего работают с изображениями, когда все элементы имеют
// одинаковый диапазон

// Функция для нормализации изображения
// Значения в пикселях должны быть от 0 до 1
// Формула (x - xmin) / (xmax - xmin)
//************************************************************************** 
function normalize(image){
  var bandNames = image.bandNames();
  // Вычислим минимум и максимум на снимке
  var minDict = image.reduceRegion({
    reducer: ee.Reducer.min(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var maxDict = image.reduceRegion({
    reducer: ee.Reducer.max(),
    geometry: geometry,
    scale: 10,
    maxPixels: 1e9,
    bestEffort: true,
    tileScale: 16
  });
  var mins = ee.Image.constant(minDict.values(bandNames));
  var maxs = ee.Image.constant(maxDict.values(bandNames));

  var normalized = image.subtract(mins).divide(maxs.subtract(mins));
  return normalized;
}

var composite = normalize(composite);
// Add a random column and split the GCPs into training and validation set
var gcp = gcp.randomColumn();

// Поскольку это более простая классификация, мы берем 60% размер валидационной выборки
// Обычно рекомендуемое соотношение составляет
// 70% обучающая, 30% валидационная
var trainingGcp = gcp.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcp.filter(ee.Filter.gte('random', 0.6));

// Наложите точку на изображение, чтобы получить обучающие данные.
var training = composite.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});
print(training);

// Обучите классификатор
var classifier = ee.Classifier.smileRandomForest(50)
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: composite.bandNames()
});

// Произведите классификацию снимка
var classified = composite.classify(classifier);

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, '2019');

// Exercise 

// Use the Export.image.toAsset() function to export the 
// classified image as a Earth Engine Asset.

// This will allows you to import the classified image in another
// script without running the whole classification workflow.

// Hint: For images with discrete pixel values, we must set the
// pyramidingPolicy to 'mode'.
// The pyramidingPolicy parameter should a dictionary specifying
// the policy for each band. A simpler way to specify it for all
// bands is to use {'.default': 'mode'}

// assetId should be specified as a string
// Lookup your asset root name from the 'Assets' tab
// If it is 'users/username', you can specify the id as
// 'users/username/classified_image'

// Упражнение 

// Используйте функцию Export.image.toAsset() для экспорта 
// классифицированного изображения в качестве Earth Engine Asset.

// Это позволит вам импортировать классифицированное изображение в другой
// скрипт без выполнения всего процесса классификации.

// Подсказка: Для изображений с дискретными значениями пикселей мы должны установить для параметра
// pyramidingPolicy значение "mode".
// Параметр pyramidingPolicy должен содержать словарь, указывающий
// политику для каждого диапазона. Более простой способ указать ее для всех
// bands должен использовать {'.default': 'mode'}

// AssetID должен быть указан в виде строки
// Найдите корневое имя вашего ресурса на вкладке "Ресурсы"
// Если это "пользователи/username", вы можете указать идентификатор как
// "пользователи/username/classified_image"
```

## 05. Вычисление площади

Теперь, когда у нас есть результаты нашей классификации, мы научимся вычислять площадь пикселей в каждом классе. Функции, используемые для вычисления площади, различны для векторных и растровых данных.

- Площадь многоугольников: Вычисление площади для многоугольников выполняется с помощью функции `area()`. Она вычисляет площадь сферы (игнорируя сглаживание эллипсоида) и выдает площадь в квадратных метрах. Вы можете дополнительно указать proj и ненулевые параметры maxError для расчета площади в конкретной проектируемой CRS. Например, area`({proj:'EPSG:32643', maxError: 1})` вычислит площадь полигона после его перепроецирования в WGS 84/UTM Zone 43 CRS с допуском в 1 метр.
- Площадь пикселей изображения: Площадь пикселей изображения вычисляется с помощью функции ee.Функция `Image.pixelArea()`. Эта функция вычисляет площадь внутри четырех углов каждого пикселя с использованием эллипсоида WGS84. ee.Функция `Image.pixelArea()` использует пользовательскую проекцию равной площади для вычисления площади. Результатом является площадь в квадратных метрах независимо от проекции входного изображения. Выучить больше.

<figure markdown>
  ![[03_05_1.jpg]]
  <figcaption>Вычисление площади зелени на классифицированном снимке</figcaption>
</figure>

```js
var classified = ee.Image('users/ujavalgandhi/e2e/bangalore_classified');
var bangalore = ee.FeatureCollection('users/ujavalgandhi/public/bangalore_boundary');

Map.addLayer(bangalore, {color: 'blue'}, 'Bangalore City');

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified, {min: 0, max: 3, palette: palette}, '2019');

// Вызов .geometry() для коллекции объектов дает
// сведенную геометрию всех объектов в коллекции

// .функция area() вычисляет площадь в квадратных метрах
var cityArea = bangalore.geometry().area();

// Мы можем преобразовать результат в ee.Number() и вычислить
// площадь в квадратных километрах
var cityAreaSqKm = ee.Number(cityArea).divide(1e6).round();
print(cityAreaSqKm);

// Высиление площади снимков
var vegetation = classified.eq(3);
// Если изображение содержит значения 0 или 1, мы можем рассчитать
// общую площадь, используя функцию reduceRegion()

// Результатом операции .eq() будет двоичное изображение с пикселями
// значения 1, если условие выполнено, и 0, если нет.
Map.addLayer(vegetation, {min:0, max:1, palette: ['white', 'green']}, 'Green Cover');

// Поскольку наше изображение имеет значения только 0 и 1 пиксель, растительность
// пиксели будут иметь значения, равные их площади
var areaImage = vegetation.multiply(ee.Image.pixelArea());


// Теперь, когда каждый пиксель для класса растительности на изображении имеет значение,
// равное его площади, мы можем суммировать все значения в регионе,
// чтобы получить общее зеленое покрытие.
var area = areaImage.reduceRegion({
  reducer: ee.Reducer.sum(),
  geometry: bangalore.geometry(),
  scale: 10,
  maxPixels: 1e10
});

// Результатом работы функции reduceRegion() является словарь с ключом,
// который является названием полосы. Мы можем извлечь номер области и преобразовать его в квадратные километры
var vegetationAreaSqKm = ee.Number(area.get('classification')).divide(1e6).round();
print(vegetationAreaSqKm);
```

### Упражнение

```js
// Вычислите и выведите площадь зелени в городе
```

## Задание 3

```js
// Выберите город по своему выбору и создайте классификацию земель для землепользования
// используя метод контролируемой классификации. 

// Вы можете использовать свой скрипт 01c из модуля 03-Контролируемая классификация
// в качестве отправной точки.

// Классификация должна включать следующие методы
// 1. Добавьте соответствующие признаки
// 2. Добавьте облачную маскировку
// 3. Добавьте высоту и уклон
// 4. Нормализуйте данные
```

!!! abstract "Перевел"
    - Павел Дмитриев
    - Алексей Луговской